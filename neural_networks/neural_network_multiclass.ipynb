{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from shutil import copyfile\n",
    "from PIL import Image\n",
    "import glob\n",
    "import piexif\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import csv\n",
    "import json\n",
    "import ast\n",
    "import datetime\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mnist_data(path, classes):\n",
    "    \"\"\"\n",
    "        Reads MNIST dataset and returns:\n",
    "        \n",
    "        X: (N X M)\n",
    "        Y: (C X M) (one-hot encoded)\n",
    "        M: Total number of examples\n",
    "        N: Total number of features\n",
    "        \n",
    "        Note: Dataset is read from local machine which in turn is retrieved from\n",
    "        https://www.kaggle.com/c/digit-recognizer/data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read data\n",
    "    df = pd.read_csv(path)\n",
    "    cols = df.columns.tolist()\n",
    "    \n",
    "    # Extract data and convert to numpy arrays\n",
    "    X = df[cols[1:]].values.T\n",
    "    Y = df[cols[0]].values.T\n",
    "\n",
    "    # Convert to one-hot encoding\n",
    "    M = X.shape[1]\n",
    "    one_hot_y = np.zeros((M, classes))\n",
    "    one_hot_y[np.arange(M), Y] = 1\n",
    "    Y = one_hot_y.T\n",
    "    \n",
    "    return X, Y, X.shape[1], X.shape[0]\n",
    "    \n",
    "def plot_mnist_example(X, Y, image_size, index=None):\n",
    "    \"\"\"\n",
    "        Given X: (N X M) and Y: (C X M), and an optional\n",
    "        index in the range (0, M-1), this function plots\n",
    "        the corresponding image\n",
    "        \n",
    "        image_size: is the size of the image (i.e. width = height = image_size)\n",
    "    \"\"\"\n",
    "\n",
    "    M = X.shape[1]\n",
    "    if index == None:\n",
    "        index = random.randint(0, M - 1) \n",
    "    image = X[:, index]\n",
    "    image = image.reshape(image.shape[0], 1)\n",
    "    print(\"Printing image no: \" + str(index))\n",
    "    image = image.reshape(image_size, image_size)\n",
    "    label = Y[:,index]\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(image)\n",
    "    plt.title(\"Label: \" + str(np.argmax(label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(x, y, train_per, dev_per, test_per):\n",
    "    \"\"\"\n",
    "        Splits dataset (i.e. x, y) into 3 parts, specified by their percentages\n",
    "        Example: split_dataset(x, y, 80, 10, 10) will split x and y into the following:\n",
    "        \n",
    "        train: 80%\n",
    "        dev: 10%\n",
    "        test: 10%\n",
    "        \n",
    "        Note: x and y should be ndarray's of size (N X M) and (C X M) respectively\n",
    "        \n",
    "        Note: You can give one of the percentage as 0. For instance, if you give (70, 0, 30), then\n",
    "        dev set size will be zero!\n",
    "    \"\"\"\n",
    "\n",
    "    new_x = x.T\n",
    "    new_y = y.T\n",
    "    \n",
    "    rows = new_x.shape[0]\n",
    "    cols = new_x.shape[1]\n",
    "    \n",
    "    combined = np.hstack((new_x, new_y))\n",
    "    np.random.shuffle(combined)\n",
    "    \n",
    "    new_x = combined[:,:cols]\n",
    "    new_y = combined[:,cols:]\n",
    "    \n",
    "    train_size = int((train_per / 100) * rows)\n",
    "    dev_size = int((dev_per / 100) * rows)\n",
    "    test_size = int((test_per / 100) * rows)\n",
    "\n",
    "    print(\"Total size: \" + str(rows) + \" Train size: \" + str(train_size) +\n",
    "          \" Dev size: \" + str(dev_size) + \" Test size: \" + str(test_size))\n",
    "    \n",
    "    train_x = new_x[:train_size]\n",
    "    dev_x = new_x[train_size:train_size + dev_size]\n",
    "    test_x = new_x[train_size + dev_size:]\n",
    "    \n",
    "    train_y = new_y[:train_size]\n",
    "    dev_y = new_y[train_size:train_size + dev_size]\n",
    "    test_y = new_y[train_size + dev_size:]\n",
    "    \n",
    "    return (train_x.T, dev_x.T, test_x.T, train_y.T, dev_y.T, test_y.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(filename, X_train, X_dev, Y_train, Y_dev, M_train, M_dev,\n",
    "               N, C, split, layers, activation_funcs, params,\n",
    "               cost, cost_arr, alpha, iterations, accuracy_train, accuracy_dev):\n",
    "    \"\"\"\n",
    "        Writes the model to a CSV file (In the form of a dictionary)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Saving model to file: \" + filename)\n",
    "    \n",
    "    my_model = {}\n",
    "    my_model[\"X_train_shape\"] = X_train.shape\n",
    "    my_model[\"Y_train_shape\"] = Y_train.shape\n",
    "    my_model[\"M_train\"] = M_train\n",
    "    my_model[\"X_dev_shape\"] = X_dev.shape\n",
    "    my_model[\"Y_dev_shape\"] = Y_dev.shape\n",
    "    my_model[\"M_dev\"] = M_dev\n",
    "    my_model[\"N\"] = N\n",
    "    my_model[\"C\"] = C\n",
    "    my_model[\"split\"] = split\n",
    "    my_model[\"layers\"] = json.dumps(layers)\n",
    "    my_model[\"activation_funcs\"] = json.dumps(activation_funcs)\n",
    "    \n",
    "    simple_params = []\n",
    "    for key, value in params.items():\n",
    "        simple_param = {}\n",
    "        simple_param[\"param_name\"] = key\n",
    "        simple_param[\"rows\"] = value.shape[0]\n",
    "        simple_param[\"cols\"] = value.shape[1]\n",
    "        simple_param[\"value\"] = json.dumps(value.reshape(-1).tolist())\n",
    "        simple_params.append(simple_param)\n",
    "    my_model[\"params\"] = json.dumps(simple_params)\n",
    "    \n",
    "    my_model[\"cost\"] = cost\n",
    "    my_model[\"cost_arr\"] = json.dumps(cost_arr)\n",
    "    my_model[\"alpha\"] = alpha\n",
    "    my_model[\"iterations\"] = iterations\n",
    "    my_model[\"accuracy_train\"] = accuracy_train\n",
    "    my_model[\"accuracy_dev\"] = accuracy_dev\n",
    "    \n",
    "    with open(filename, 'w') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        for key, value in my_model.items():\n",
    "           writer.writerow([key, value])\n",
    "\n",
    "def read_model(filename):\n",
    "    \n",
    "    \"\"\"\n",
    "        Reads the model from the file 'filename'\n",
    "        Note: The model should have been saved to this file\n",
    "        in the format specified by save_model\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Reading model from file: \" + filename)\n",
    "    \n",
    "    with open(filename, 'r') as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        my_model = dict(reader)\n",
    "        \n",
    "    my_model[\"X_train_shape\"] = ast.literal_eval(my_model[\"X_train_shape\"])\n",
    "    my_model[\"Y_train_shape\"] = ast.literal_eval(my_model[\"Y_train_shape\"])\n",
    "    my_model[\"M_train\"] = int(my_model[\"M_train\"])\n",
    "    my_model[\"X_dev_shape\"] = ast.literal_eval(my_model[\"X_dev_shape\"])\n",
    "    my_model[\"Y_dev_shape\"] = ast.literal_eval(my_model[\"Y_dev_shape\"])\n",
    "    my_model[\"M_dev\"] = int(my_model[\"M_dev\"])\n",
    "    my_model[\"N\"] = int(my_model[\"N\"])\n",
    "    my_model[\"C\"] = int(my_model[\"C\"])\n",
    "    my_model[\"split\"] = ast.literal_eval(my_model[\"split\"])\n",
    "    my_model[\"layers\"] = json.loads(my_model[\"layers\"])\n",
    "    my_model[\"activation_funcs\"] = json.loads(my_model[\"activation_funcs\"])\n",
    "    \n",
    "    my_model[\"params\"] = json.loads(my_model[\"params\"])\n",
    "    params = {}\n",
    "    for simple_param in my_model[\"params\"]:\n",
    "        np_list_value = np.array(json.loads(simple_param[\"value\"]), dtype=np.float64)\n",
    "        value = np_list_value.reshape(int(simple_param[\"rows\"]), int(simple_param[\"cols\"]))\n",
    "        params[simple_param[\"param_name\"]] = value\n",
    "    my_model[\"params\"] = params\n",
    "        \n",
    "    my_model[\"cost\"] = float(my_model[\"cost\"])\n",
    "    my_model[\"cost_arr\"] = json.loads(my_model[\"cost_arr\"])\n",
    "    my_model[\"alpha\"] = float(my_model[\"alpha\"])\n",
    "    my_model[\"iterations\"] = int(my_model[\"iterations\"])\n",
    "    my_model[\"accuracy_train\"] = float(my_model[\"accuracy_train\"])\n",
    "    my_model[\"accuracy_dev\"] = float(my_model[\"accuracy_dev\"])\n",
    "    \n",
    "    return my_model\n",
    "\n",
    "def print_model(model_dict, func_names):\n",
    "    print(\"=\" * 40)\n",
    "    print(\"Layers : \" + str(model_dict[\"layers\"]))\n",
    "    print_activation_function_names(func_names, model_dict[\"activation_funcs\"])\n",
    "    print(\"Alpha : \" + str(model_dict[\"alpha\"]))\n",
    "    print(\"Iterations : \" + str(model_dict[\"iterations\"]))\n",
    "    print(\"Cost : \" + str(model_dict[\"cost\"]))\n",
    "    print(\"Accuracy(train) : \" + str(model_dict[\"accuracy_train\"]))\n",
    "    print(\"Accuracy(dev) : \" + str(model_dict[\"accuracy_dev\"]))\n",
    "    print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(vec):\n",
    "    \"\"\"\n",
    "        vec is a row/column vector\n",
    "        Returns a normalized vector\n",
    "    \"\"\"\n",
    "    mew = np.average(vec)\n",
    "    std = np.std(vec)\n",
    "    return (mew, std, (vec - mew)/std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def de_normalize(mew, std, vec):\n",
    "    \"\"\"\n",
    "        mew and std are numbers denoting the original mean and standard deviation of the vector\n",
    "        Returns the denormalized vector\n",
    "    \"\"\"\n",
    "    return ((vec * std) + mew) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Computes the sigmoid of z\n",
    "    \"\"\"\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(z):\n",
    "    \"\"\"\n",
    "    Applies the sigmoid-derivative on z\n",
    "    \"\"\"\n",
    "    return sigmoid(z) * (1 - sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(z):\n",
    "    \"\"\"\n",
    "    Computes the tanh of z\n",
    "    \"\"\"\n",
    "    return (np.exp(z) - np.exp(-z))/(np.exp(z) + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh_derivative(z):\n",
    "    \"\"\"\n",
    "    Applies the tanh-derivative on z\n",
    "    \"\"\"\n",
    "    return (1 - tanh(z)) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    \"\"\"\n",
    "    Computes the Rectified Linear Unit of z\n",
    "    \"\"\"\n",
    "    return np.maximum(z, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_derivative(z):\n",
    "    \"\"\"\n",
    "    Applies the ReLU derivative on z\n",
    "    \"\"\"\n",
    "    return (z > 0).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(z):\n",
    "    \"\"\"\n",
    "    Computes the Leaky Rectified Linear Unit of z\n",
    "    \"\"\"\n",
    "    return np.maximum(z, 0.01 * z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu_derivative(z):\n",
    "    \"\"\"\n",
    "    Applies the leaky_ReLU derivative on z\n",
    "    \"\"\"\n",
    "    f = np.vectorize(lambda x : 1 if x > 0 else 0.01, otypes=[np.float])\n",
    "    return f(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_activation_function_names(func_names, indices):\n",
    "    print(\"Activation functions: \", end=\"\")\n",
    "    for i in range(len(indices)):\n",
    "        print(func_names[indices[i]].__name__, end=\"\")\n",
    "        if i != (len(indices) - 1):\n",
    "            print(\" -> \", end=\"\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(layer_sizes):\n",
    "    \"\"\"\n",
    "        Initializes the neural network model\n",
    "        \n",
    "        Input is a list containing the lengths of the layer\n",
    "    \"\"\"\n",
    "    \n",
    "    assert(len(layer_sizes) >= 2)\n",
    "    parameters = {}\n",
    "    \n",
    "    # initialize the parameters\n",
    "    for i in range(1, len(layer_sizes)):\n",
    "        parameters[\"W\" + str(i)] = np.random.randn(layer_sizes[i], layer_sizes[i - 1]) * 0.01\n",
    "        parameters[\"b\" + str(i)] = np.zeros((layer_sizes[i], 1))\n",
    "        \n",
    "    return parameters\n",
    "\n",
    "def unit_test_initialize_model():\n",
    "    layers = [2, 3, 10, 10, 3, 1]\n",
    "    params = initialize_model(layers)\n",
    "    for i in range(1, len(layers)):\n",
    "        W = params['W' + str(i)]\n",
    "        b = params['b' + str(i)]\n",
    "        print(\"Shape of W\" + str(i) + \" is: \" + str(W.shape) + \" and b\" + str(i) + \" is: \" + str(b.shape))\n",
    "        \n",
    "# unit_test_initialize_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(X, parameters, layer_sizes, funcs, activation_funcs):\n",
    "    \"\"\"\n",
    "        X -- of size (N X M)\n",
    "        parameters -- a dictionary of W's and b's of appropriate shapes\n",
    "        layer_sizes -- a list of layer sizes of the network\n",
    "        funcs -- list of available activation functions (i.e. an array of functions)\n",
    "        activation_funcs -- list of activation functions (i.e. an index into func_names)\n",
    "        \n",
    "        returns the final activation result and caches tuple, which holds all intermediate results\n",
    "        useful for backprop\n",
    "    \"\"\"\n",
    "    \n",
    "    assert((len(layer_sizes) >= 2) and (len(activation_funcs) == (len(layer_sizes) - 1)))\n",
    "    \n",
    "    # feed-forward propagation\n",
    "    prev_A = X\n",
    "    caches = []\n",
    "    for i in range(1, len(layer_sizes)):\n",
    "\n",
    "        W = parameters[\"W\" + str(i)]\n",
    "        b = parameters[\"b\" + str(i)]\n",
    "        \n",
    "        Z = W @ prev_A + b\n",
    "        \n",
    "        linear_cache = prev_A, W, b\n",
    "        activation_cache = Z\n",
    "        \n",
    "        A = funcs[activation_funcs[i - 1]](Z)\n",
    "        \n",
    "        \n",
    "        cache = linear_cache, activation_cache\n",
    "        caches.append(cache)\n",
    "\n",
    "        prev_A = A\n",
    "        \n",
    "    return prev_A, caches\n",
    "\n",
    "def unit_test_forward_propagate():\n",
    "    X = np.random.randn(3, 5)\n",
    "    layers = [3, 4, 2, 1]\n",
    "    parameters = initialize_model(layers)\n",
    "    funcs = [sigmoid, tanh, relu, leaky_relu]\n",
    "    activation_funcs = [1, 2, 3]\n",
    "    final_activation, caches = forward_propagate(X, parameters, layers, funcs, activation_funcs)\n",
    "    for i in range(1, len(layers)):\n",
    "        W = parameters['W' + str(i)]\n",
    "        b = parameters['b' + str(i)]\n",
    "        print(\"Shape of W\" + str(i) + \" is: \" + str(W.shape) + \" and b\" + str(i) + \" is: \" + str(b.shape))\n",
    "        print(W)\n",
    "        print(b)\n",
    "        linear_cache, activation_cache = caches[i - 1]\n",
    "        A, W, b = linear_cache\n",
    "        Z = activation_cache\n",
    "        print(\"Linear cache A is: \")\n",
    "        print(A)\n",
    "        print(\"Activation cache is: \")\n",
    "        print(Z)\n",
    "\n",
    "    print(\"Final activation is: \")\n",
    "    print(final_activation)\n",
    "    \n",
    "# unit_test_forward_propagate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_cost(A, Y):\n",
    "    \"\"\"\n",
    "    Computes the standard cross entropy cost on A (of size CXM) and Y of size (CXM), where C is no:of classes\n",
    "    \"\"\"\n",
    "    M = A.shape[1]\n",
    "    cost = (-1/M) * np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A), axis=1, keepdims=True)\n",
    "    \"\"\"\n",
    "        The above cost array will be of size (C X 1)\n",
    "        We need average cost since we are doing multi-class classification\n",
    "    \"\"\"\n",
    "    avg_cost = np.squeeze(np.mean(cost))\n",
    "    return avg_cost\n",
    "\n",
    "def cross_entropy_derivative(A, Y):\n",
    "    \"\"\"\n",
    "        Computes the derivative of cross_entropy_loss function with respect to the last layer\n",
    "        activations\n",
    "    \"\"\"\n",
    "    M = A.shape[1]\n",
    "    return (-1) * (np.divide(Y, A) - np.divide(1 - Y, 1 - A))\n",
    "\n",
    "def unit_test_cross_entropy_cost():\n",
    "    a = np.array([0.1, 0.1]).reshape(1, 2)\n",
    "    b = np.array([0.9, 0.9]).reshape(1, 2)\n",
    "    print(a)\n",
    "    print(b)\n",
    "    print(cross_entropy_cost(a, b))\n",
    "    \n",
    "# unit_test_cross_entropy_cost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagate(AL, Y, caches, derivative_funcs, activation_funcs, cost_func_derivative):\n",
    "    \"\"\"\n",
    "    Computes backward propagation on a neural network, given:\n",
    "    \n",
    "    AL: Activations of last layer (C X M) where C is the no:of classes\n",
    "    Y: Actual output values (C X M)\n",
    "    caches: Intermediate results accumulated during forward propagation\n",
    "    derivative_funcs -- derivative functions of list of available activation functions (i.e. an array of functions)\n",
    "    activation_funcs -- list of activation functions (i.e. an index into func_names)\n",
    "        \n",
    "    returns a dictionary of gradients\n",
    "    \"\"\"\n",
    "    \n",
    "    grads = {}\n",
    "    assert(len(caches) >= 1)\n",
    "    assert(Y.shape == AL.shape)\n",
    "    \n",
    "    L = len(caches)\n",
    "    m = Y.shape[1]\n",
    "    linear_cache, activation_cache = caches[L - 1]\n",
    "    A_prev, W, b = linear_cache\n",
    "\n",
    "    # Differentiation of the cross_entropy loss function with respect to 'AL' (i.e. the last layer activations)\n",
    "    dAL = cost_func_derivative(AL, Y)    \n",
    "    dZL = dAL * derivative_funcs[activation_funcs[L-1]](activation_cache)\n",
    "    grads[\"dW\" + str(L)] = (1/m) * (dZL @ A_prev.T)\n",
    "    grads[\"db\" + str(L)] = (1/m) * np.sum(dZL, axis=1, keepdims=True)\n",
    "    grads[\"dA\" + str(L - 1)] = (W.T @ dZL)\n",
    "    \n",
    "    # Loop from l=L-2 to l=0 inclusive\n",
    "    for l in reversed(range(L-1)):\n",
    "        \n",
    "        cache = caches[l]\n",
    "        linear_cache, activation_cache = cache\n",
    "        A_prev, W, b = linear_cache\n",
    "\n",
    "        dZ = grads[\"dA\" + str(l + 1)] * derivative_funcs[activation_funcs[l]](activation_cache)\n",
    "        grads[\"dW\" + str(l + 1)] = (1/m) * (dZ @ A_prev.T)\n",
    "        grads[\"db\" + str(l + 1)] = (1/m) * np.sum(dZ, axis=1, keepdims=True)\n",
    "        grads[\"dA\" + str(l)] = (W.T @ dZ)\n",
    "        \n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "        Update parameters using gradient descent\n",
    "\n",
    "        Arguments:\n",
    "        params - dictionary containing parameters \n",
    "        grads - dictionary containing gradients\n",
    "\n",
    "        Returns: updated parameter dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    # get the number of layers in the neural network\n",
    "    L = len(parameters) // 2\n",
    "\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, learning_rate, layers, iterations, funcs, derivative_funcs, activation_funcs,\n",
    "          cost_func=cross_entropy_cost, cost_func_derivative=cross_entropy_derivative):\n",
    "    \"\"\"\n",
    "        X - input feature vector of size (N X M)\n",
    "        Y - output label of size (1 X M)\n",
    "        \n",
    "        learning_rate - alpha\n",
    "        layers - a python list denoting the layers of the network\n",
    "        iterations - number of iterations to run gradient descent\n",
    "        funcs - list of activation functions (function pointers)\n",
    "        derivative_funcs - list of derivative functions of the activation functions (function pointers)\n",
    "        activation_funcs - list, denoting which activation function to be used on each layer\n",
    "        cost_func - the cost function which has to be used for fitting the model\n",
    "        \n",
    "        returns the parameter dictionary containing the weights of the learned model and the corresponding cost\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "        General procedure for learning:\n",
    "\n",
    "        1. Initialize parameters\n",
    "        2. Loop for num_iterations:\n",
    "            a. Forward propagation\n",
    "            b. Compute cost function\n",
    "            c. Backward propagation\n",
    "            d. Update parameters (using parameters, and grads from backprop)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    params = initialize_model(layers)\n",
    "    cost_arr = []\n",
    "    \n",
    "    i = 0\n",
    "    while i != iterations:\n",
    "        \n",
    "        AL, caches = forward_propagate(X, params, layers, funcs, activation_funcs)\n",
    "        cost = cost_func(AL, Y)\n",
    "        cost_arr.append(cost)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(\"At \" + str(i) + \"th iteration, cost is: \" + str(cost))\n",
    "            \n",
    "        grads = backward_propagate(AL, Y, caches, derivative_funcs, activation_funcs, cost_func_derivative)\n",
    "        params = update_parameters(params, grads, learning_rate)\n",
    "        \n",
    "        i = i + 1\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.plot(cost_arr)\n",
    "    plt.ylabel(\"Cross entropy cost\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.title(\"Gradient descent progress\")\n",
    "    \n",
    "    return params, cost_arr[-1], cost_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, Y, params, layers, funcs, activation_funcs, classes):\n",
    "    '''\n",
    "        Performs the prediction, given the weights of the model (by doing a forward propagation)\n",
    "        The predicted results are then compared with the actual values (1's and 0's) present in 'Y'\n",
    "        \n",
    "        Before comparing with 'Y', the predicted results are classified as 1 if activation value is > 0\n",
    "        else as 0\n",
    "        \n",
    "        layers - the layers present in model (as a python list)\n",
    "        funcs - list of activation functions (function pointers)\n",
    "        activation_funcs - list, denoting which activation function to be used on each layer\n",
    "        \n",
    "        Returns the prediction results and the accuracy\n",
    "    '''\n",
    "    \n",
    "    AL, caches = forward_propagate(X, params, layers, funcs, activation_funcs)\n",
    "    \n",
    "    predictions = np.argmax(AL, axis=0)\n",
    "    actual_values = np.argmax(Y, axis=0)\n",
    "    \n",
    "    accuracy = np.mean(np.equal(predictions, actual_values)) * 100\n",
    "\n",
    "    M = X.shape[1]\n",
    "    Y_prediction = np.zeros((M, classes))\n",
    "    Y_prediction[np.arange(M), predictions] = 1\n",
    "    Y_prediction = Y_prediction.T\n",
    "    Y_prediction = Y_prediction.astype(int)\n",
    "    \n",
    "    return Y_prediction, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_incorrectly_labelled_examples(X, Y, Y_prediction, image_size):\n",
    "    \"\"\"\n",
    "        Given X: (N X M), Y and Y_prediction: (C X M), this functions prints few of the\n",
    "        incorrectly labelled examples\n",
    "        \n",
    "        Note: Y_prediction is the predicted output of the model, corresponding to X and Y\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract the mismatches\n",
    "    predictions = np.argmax(Y_prediction, axis=0)\n",
    "    actual_values = np.argmax(Y, axis=0)\n",
    "    mismatches = np.flatnonzero(np.logical_not(np.equal(predictions, actual_values)))\n",
    "    print(\"Total mislabelled examples are: \" + str(mismatches.size) + \" out of: \" + str(Y.shape[1]))\n",
    "    \n",
    "    if(mismatches.size != 0):\n",
    "        # Randomly select an index which is mismatched\n",
    "        index = mismatches[random.randint(0, mismatches.size - 1)]\n",
    "        \n",
    "        # Print the predicted label, which is incorrect\n",
    "        predicted_label = Y_prediction[:,index]\n",
    "        \n",
    "        image = X[:, index]\n",
    "        image = image.reshape(image.shape[0], 1)\n",
    "        image = image.reshape(image_size, image_size)\n",
    "        label = Y[:,index]\n",
    "        fig = plt.figure()\n",
    "        plt.imshow(image)\n",
    "        plt.title(\"Actual Label: \" + str(np.argmax(label)) + \" Predicted: \" + str(np.argmax(predicted_label)))\n",
    "        \n",
    "    else:\n",
    "        print(\"No incorrectly labelled examples found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples (M): 42000\n",
      "Total no:of features (N): 784\n",
      "X: (784, 42000)\n",
      "Y: (10, 42000)\n",
      "Total size: 42000 Train size: 29399 Dev size: 8400 Test size: 4200\n",
      "X_train: (784, 29399)\n",
      "X_dev: (784, 8400)\n",
      "X_test: (784, 4201)\n",
      "Y_train: (10, 29399)\n",
      "Y_dev: (10, 8400)\n",
      "Y_test: (10, 4201)\n",
      "Printing image no: 7584\n",
      "At 0th iteration, cost is: 0.677669531223948\n",
      "At 100th iteration, cost is: 0.11577315282910994\n",
      "At 200th iteration, cost is: 0.0896096599204593\n",
      "At 300th iteration, cost is: 0.07860747378288085\n",
      "At 400th iteration, cost is: 0.07190868310064268\n",
      "At 500th iteration, cost is: 0.06767659296667741\n",
      "At 600th iteration, cost is: 0.06468084845310607\n",
      "At 700th iteration, cost is: 0.062320607375849726\n",
      "At 800th iteration, cost is: 0.06041873931417867\n",
      "At 900th iteration, cost is: 0.05885107437788596\n",
      "At 1000th iteration, cost is: 0.05753901294741629\n",
      "At 1100th iteration, cost is: 0.05640414976892849\n",
      "At 1200th iteration, cost is: 0.0554131335471435\n",
      "At 1300th iteration, cost is: 0.05452702515028487\n",
      "At 1400th iteration, cost is: 0.05373131033389461\n",
      "At 1500th iteration, cost is: 0.05302564871309873\n",
      "At 1600th iteration, cost is: 0.05238489302593301\n",
      "At 1700th iteration, cost is: 0.051782794526634625\n",
      "At 1800th iteration, cost is: 0.051228375890252864\n",
      "At 1900th iteration, cost is: 0.05072143104767231\n",
      "At 2000th iteration, cost is: 0.0502564027487481\n",
      "At 2100th iteration, cost is: 0.049818800287139905\n",
      "At 2200th iteration, cost is: 0.04954687913022478\n",
      "At 2300th iteration, cost is: 0.04936305178220982\n",
      "At 2400th iteration, cost is: 0.04910334387842407\n",
      "At 2500th iteration, cost is: 0.04862115315416573\n",
      "At 2600th iteration, cost is: 0.04847649554483115\n",
      "At 2700th iteration, cost is: 0.048113545540178666\n",
      "At 2800th iteration, cost is: 0.04792943945059332\n",
      "At 2900th iteration, cost is: 0.04753168966257318\n",
      "\n",
      "\n",
      "****************************************\n",
      "Train Examples: 29399\n",
      "Layers: [784, 10, 10]\n",
      "Activation functions: relu -> sigmoid\n",
      "Alpha: 0.001 iterations: 3000\n",
      "Min cost is: 0.04740753102287099\n",
      "Accuracy on train set: 93.71067043096704\n",
      "Accuracy on dev set: 92.34523809523809\n",
      "****************************************\n",
      "\n",
      "\n",
      "Saving model to file: model_2019_01_28_16_36_20.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1142db710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1142cc198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the dataset\n",
    "path = './mnist/train.csv'\n",
    "image_size = 28\n",
    "classes = 10\n",
    "X, Y, M, N = read_mnist_data(path, classes)\n",
    "print(\"Total examples (M): \" + str(M))\n",
    "print(\"Total no:of features (N): \" + str(N))\n",
    "print(\"X: \" + str(X.shape))\n",
    "print(\"Y: \" + str(Y.shape))\n",
    "\n",
    "# Dataset parameters\n",
    "train_per = 70\n",
    "dev_per = 20\n",
    "test_per = 10\n",
    "split = (train_per, dev_per, test_per)\n",
    "\n",
    "# Split the dataset\n",
    "split = (train_per, dev_per, test_per)\n",
    "(X_train, X_dev, X_test, Y_train, Y_dev, Y_test) = split_dataset(X, Y, train_per, dev_per, test_per)\n",
    "\n",
    "M_train = X_train.shape[1]\n",
    "M_dev = X_dev.shape[1]\n",
    "\n",
    "print(\"X_train: \" + str(X_train.shape))\n",
    "print(\"X_dev: \" + str(X_dev.shape))\n",
    "print(\"X_test: \" + str(X_test.shape))\n",
    "print(\"Y_train: \" + str(Y_train.shape))\n",
    "print(\"Y_dev: \" + str(Y_dev.shape))\n",
    "print(\"Y_test: \" + str(Y_test.shape))\n",
    "\n",
    "# Plot some random image from training set\n",
    "plot_mnist_example(X_train, Y_train, image_size)\n",
    "\n",
    "\"\"\"\n",
    "Total examples (M): 42000\n",
    "Total no:of features (N): 784\n",
    "X: (784, 42000)\n",
    "Y: (10, 42000)\n",
    "Total size: 42000 Train size: 29399 Dev size: 8400 Test size: 4200\n",
    "X_train: (784, 29399)\n",
    "X_dev: (784, 8400)\n",
    "X_test: (784, 4201)\n",
    "Y_train: (10, 29399)\n",
    "Y_dev: (10, 8400)\n",
    "Y_test: (10, 4201)\n",
    "\"\"\"\n",
    "\n",
    "funcs = [sigmoid, tanh, relu, leaky_relu]\n",
    "derivative_funcs = [sigmoid_derivative, tanh_derivative, relu_derivative, leaky_relu_derivative]\n",
    "\n",
    "# Network parameters\n",
    "layers = [784, 10, 10]\n",
    "activation_funcs = [2, 0]\n",
    "alpha = 0.001\n",
    "iterations = 3000\n",
    "\n",
    "params, cost, cost_arr = model(X_train, Y_train, alpha, layers, iterations, funcs,\n",
    "                                   derivative_funcs, activation_funcs, cost_func=cross_entropy_cost,\n",
    "                                   cost_func_derivative=cross_entropy_derivative)\n",
    "\n",
    "# Results\n",
    "print(\"\\n\\n\" + (\"*\" * 40))\n",
    "print(\"Train Examples: \" + str(M_train))\n",
    "print(\"Layers: \" + str(layers))\n",
    "print_activation_function_names(funcs, activation_funcs)\n",
    "print(\"Alpha: \" + str(alpha) + \" iterations: \" + str(iterations))\n",
    "print(\"Min cost is: \" + str(cost))\n",
    "Y_prediction_train, accuracy_train = predict(X_train, Y_train, params, layers, funcs, activation_funcs, classes)\n",
    "Y_prediction_dev, accuracy_dev = predict(X_dev, Y_dev, params, layers, funcs, activation_funcs, classes)\n",
    "print(\"Accuracy on train set: \" + str(accuracy_train))\n",
    "print(\"Accuracy on dev set: \" + str(accuracy_dev))\n",
    "print((\"*\" * 40) + \"\\n\\n\")\n",
    "\n",
    "# Save the model to disk\n",
    "filename = 'model_' + '{:%Y_%m_%d_%H_%M_%S}'.format(datetime.datetime.now()) + '.csv'\n",
    "save_model(filename, X_train, X_dev, Y_train, Y_dev, M_train, M_dev,\n",
    "           N, classes, split, layers, activation_funcs, params,\n",
    "           cost, cost_arr, alpha, iterations, accuracy_train, accuracy_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model from file: ./model_2019_01_28_16_36_20.csv\n",
      "========================================\n",
      "Layers : [784, 10, 10]\n",
      "Activation functions: relu -> sigmoid\n",
      "Alpha : 0.001\n",
      "Iterations : 3000\n",
      "Cost : 0.04740753102287099\n",
      "Accuracy(train) : 93.71067043096704\n",
      "Accuracy(dev) : 92.34523809523809\n",
      "========================================\n",
      "Total mislabelled examples are: 643 out of: 8400\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAFEZJREFUeJzt3XnQHHWdx/H3hyQkIYQjCcaQExAPwCXAI8ghxuVYREvwWISyIOIRqQXFY63FY9e4rpSlgrLC4kZFgyKK6wG1sgpGERFEAgYIBOQKhpiDkIQchORJ8t0/umNNnjzzm+d55kx+n1fV1DPT3+7p79Mzn5me7p5pRQRmlp/d2t2AmbWHw2+WKYffLFMOv1mmHH6zTDn8Zply+JtM0jRJzzThfhdKOrnV07aTpHdLuqPi9jpJB7ZgvrdJel+z59Nqu3z4ywdulaShfRx/iqSQNLjZvZXzC0kva8W8BkLSxyXNl7RW0lOSPp4Yd9uyW1deFkq6pFm9RcSeEfFkapw2PJ5fr/j/10naKGltK+bdX7t0+CVNAV4HBPCWtjaz8xJwHrAvcBpwkaSza0yzT0TsCZwD/Juk03a40xaFsdUi4oLyRWnPchlcD/yo3X31ZpcOP8WT9g/Ad4DplQVJwyVdJulpSc9LukPScOD2cpTV5Sv3sZJmSvpexbTbvZtIOl/SgvLd8UlJH6i3cUkHSfq1pOckrZB0naR9eoz2GkkPl2s235Y0rGL6N0uaJ2m1pDsl/d1A+oiIL0bEfRGxOSIeBW4Eju/jtHcBDwGHlT2FpAslPQY8Vg57paRbJa2U9Kiksyr+h9GSbpK0RtIfgYMq779yrak/j2c5/nvKx2yVpF9Kmlxxv6dIeqS8nyspXgD7TdII4O3A7IFM33QRsctegMeBfwKOArqBsRW1q4DbgPHAIOA4YCgwhWJNYXDFuDOB71Xc3m4c4E0UT0wBrwdeAI4sa9OAZxI9BvCyXoa/DDil7Gk/iifxVyvqC4H5wERgFPB74D/K2hHAcuCY8n+bXo4/tGLak8vrJwCr+7g8BfwJuKBK/W/LpRz3+HJZnFTxv95a9jscGAEsAs4vpzkCWAEcUo7/A+CGcrzDgMXAHb0tu34+nmeUz41XlfP9NHBnWRsDrAXeAQwBPgJsBt5X1icBq4FJfVhe5wFPAmp3Fnrtr90NNO0fK57U3cCY8vYjwEfK67sBG4DDU0/gimEzSYS/l/v4GXBxeX0aAwh/L+OdCfyp4vbCyhACpwNPlNevBj7XY/pHgddXTHvyAJbpZ4H7KV9EEstuNbAKWAB8qMf/+vcVt98J/K7Hffw38JkywN3AKytql/YW/gE8nv8HvLfi9m4UL1KTy8D+oaIm4Jlt4e/n8poDzGx3FqpddsnPXaXpwC0RsaK8/f1y2FcoXt2HAU80YkaS3kjxhH05xRNpD+DBOu9zLHAFxTaLkeX9ruox2qKK608D+5fXJwPTJX2wor57RX0g/VxEEYzXRcTGGqOPiYjNVWqVPU8GjpG0umLYYOC7FGs7g9nxf+x1fvTv8ZwMXCHpsopholhr2L9ynhERkhbRT5ImUbzwv7+/07bKLhn+8rPeWcAgSUvLwUOBfSQdThHMFylW1e/vMXlvX3NcTxHobV5aMa+hwI8pgnFjRHRL+hkD/JxY4dKyl1dHxEpJZwJX9hhnYsX1ScBfy+uLgM9HxOfr7AEoPh8DlwAnRkS9uy0rl+8i4LcRcUov8xxEsbo9kWKtDYr/sTcr6N/juW35XNfLfA+mYrlKEtsv5746F/h91Ngb0U676ga/M4EtwCHA1PLyKuB3wHkRsRW4Brhc0v6SBpUb9oYCzwJbgcr9x/OAEyVNkrQ38ImK2u4ULyzPApvLtYBT+9nv7pKGVVwGUbzbrwOelzQe6G0X24WSJkgaBXwK+GE5/BvABZKOUWGEpDdJGtnPvpD0LooXolOa8ET+X+Dlks6VNKS8vEbSqyJiC/ATYKakPSQdQo+NttsM4PH8OvAJSYeW/+Pekv6xrP0cOFTS28oNuh+i4sW+H86j2NDcudr9uaMZF+AXwGW9DD8LWEqxxjMc+CrFRqTnKTaoDS/H+3eKJ81q4LXlsKvK249TrMpVbvC7EFhW1r9LsaFq28a3adT+zN/z8j7gUOBeiheAecDHKu+H4nP7J4CHy/nOBvaoqJ8G3FPWllDsbhpZMe22DX6vA9Yl+nuK4rP3uorL16uMO4X0tpAdtm8Ar6AI3LPAc8CvgallbT+KF4g1wB+Bz1F9g19/H89zKdYA11CsCVzTY9n9ubyfK4Hfsv0Gv3UkNvgBx1KsLY5sdxZSF5XNmllmdtXVfjOrweE3y5TDb5Yph98sUy3dz7+7hsYwRrRylmZZeZH1bIqNfTrGpK7wl9/WuoLiUMxvRsQXUuMPYwTH6KR6ZmlmCXfHnD6PO+DV/vJAlKuAN1IcTHNOeSCGme0E6vnMfzTweEQ8GRGbKA5sOaMxbZlZs9UT/vFs/6WLZ8ph25E0Q9JcSXO7qfV9EDNrlaZv7Y+IWRHRFRFdQ+jTL2mZWQvUE/7FbP9tpwnlMDPbCdQT/nuAgyUdIGl34Gzgpsa0ZWbNNuBdfRGxufyBh19S7Oq7JiIealhnZtZUde3nj4ibgZsb1IuZtZAP7zXLlMNvlimH3yxTDr9Zphx+s0w5/GaZcvjNMuXwm2XK4TfLlMNvlimH3yxTDr9Zphx+s0w5/GaZcvjNMuXwm2XK4TfLlMNvlimH3yxTDr9Zphx+s0w5/GaZcvjNMuXwm2XK4TfLlMNvlimH3yxTDr9Zphx+s0w5/GaZqusU3ZIWAmuBLcDmiOhqRFNm1nx1hb/0hohY0YD7MbMW8mq/WabqDX8At0i6V9KM3kaQNEPSXElzu9lY5+zMrFHqXe0/ISIWS3oJcKukRyLi9soRImIWMAtgL42KOudnZg1S1zt/RCwu/y4Hfgoc3YimzKz5Bhx+SSMkjdx2HTgVmN+oxsysuepZ7R8L/FTStvv5fkT8oiFdmVnTDTj8EfEkcHgDezGzFvKuPrNMOfxmmXL4zTLl8JtlyuE3y5TDb5Yph98sUw6/WaYcfrNMOfxmmXL4zTLl8JtlyuE3y1QjfsDTdmLqOiw9QqR/fKl772HJ+uBf39vflqxF/M5vlimH3yxTDr9Zphx+s0w5/GaZcvjNMuXwm2XK+/lLgw+ckqyvPmps1Zre+2xy2mNf8tRAWuqz1d17VK396k+HJqe9+uTZyfqmGJSsv3Tw88n69LnvqVobdUP1vgE2nLs6WT9pwp+T9VuuPbZqbfAL6eMXxsy6K1nfFfid3yxTDr9Zphx+s0w5/GaZcvjNMuXwm2XK4TfL1C6zn/+pS6vv0wWYemJ6n/Bx+85L1i/c54l+99QRJtyeLA9Rej/+TevT++J/vmZqsv4PBy6oWrv4y7clp50weHiyXsvQd2+uWrv+wa7ktGNm1TXrnULNd35J10haLml+xbBRkm6V9Fj5d9/mtmlmjdaX1f7vAKf1GHYJMCciDgbmlLfNbCdSM/wRcTuwssfgM4Btx4XOBs5scF9m1mQD/cw/NiKWlNeXAlUPfJc0A5gBMIz050cza526t/ZHRABVvyUREbMioisiuoYwtN7ZmVmDDDT8yySNAyj/Lm9cS2bWCgMN/03A9PL6dODGxrRjZq2iqPG77JKuB6YBY4BlwGeAnwE3AJOAp4GzIqLnRsEd7KVRcYxOqrPl3r3l4eeS9fP3Su+nr7W/O2XJlg3J+p0bJibrb99zRbL+mw3p38Z/dOP+yXrKtV8+PVkf/cCaZF2PLEzWt65fX7W24cyjk9MO/eCSZP3c8env3J8zclnV2guxKTntSTM/mqyP/mZnft//7pjDmlipvoxbc4NfRJxTpdScFJtZS/jwXrNMOfxmmXL4zTLl8JtlyuE3y1TNXX2N1MxdfbW8fUH6OKSjh6V/Xnv11upfL734yguS00740dPJ+uK3TU7Wx92W3ou69YFHkvWd1fKLjkvWn3/llmT90bf+14Dn/dln019VvmfqwHcNN1N/dvX5nd8sUw6/WaYcfrNMOfxmmXL4zTLl8JtlyuE3y1Q2+/lr0WtenawPWlT9OIHNS6t/dTR3Glr915s2H5s+ffhHvvn9ZP3U4dW/Ltxsbx5/VNvmneL9/GZWk8NvlimH3yxTDr9Zphx+s0w5/GaZcvjNMrXLnKK7XnHPg8l69ZM9W8pz7zqyau3Oz13Zwk62t2rri8n6Cdf9c7J+AJ3509394Xd+s0w5/GaZcvjNMuXwm2XK4TfLlMNvlimH3yxT3s9vdYnj079vf9W//mfV2m7U99v38zalj744+4cXV60deEl6P/2usB+/lprv/JKukbRc0vyKYTMlLZY0r7ykT/JuZh2nL6v93wFO62X4VyJianm5ubFtmVmz1Qx/RNwOpM8XZWY7nXo2+F0k6YHyY8G+1UaSNEPSXElzu9lYx+zMrJEGGv6rgYOAqcAS4LJqI0bErIjoioiuIVT/MUcza60BhT8ilkXElojYCnwDOLqxbZlZsw0o/JLGVdx8KzC/2rhm1plq7ueXdD0wDRgj6RngM8A0SVOBABYCH2hij1bDbsOGVa1t/vl+yWn/cteEZP3mc7+UrI/c7ffJ+r67Ve9tK/WdM+LOFw5O1mvty89dzfBHxDm9DP5WE3oxsxby4b1mmXL4zTLl8JtlyuE3y5TDb5Ypf6W3Bda+87XJ+vqXpl+D979tVbL++Lv2qVrbsmhTctpba+zKmzR4eLJej6Mu/2Cy/tH3/0/T5m1+5zfLlsNvlimH3yxTDr9Zphx+s0w5/GaZcvjNMqWI+r5W2R97aVQco5NaNr9Osfcdo5P16w64JVn/zYbqX4sFGD1ofb972mbq7ulDPer92u3XVlX/2u1xezyWnPaoGj/8NGPRtGT9+U3Vl9uR+yxKTnvH+Ucl63HvQ8l6u9wdc1gTK9WXcf3Ob5Yph98sUw6/WaYcfrNMOfxmmXL4zTLl8Jtlyt/nb4H7/jIxPcIB6fIbhr9YYw71neq6HrWOQViwflzV2srNI5LTXrL8oGR9xHkbkvUXDk8s9y+l9/MPWpU+diJ9cvCdg9/5zTLl8JtlyuE3y5TDb5Yph98sUw6/WaYcfrNM9eUU3ROBa4GxFKfknhURV0gaBfwQmEJxmu6zIiL9A/OZOvBr6e/Ef+mwQ5L1j49+OFnfGN1Va59edkJy2iHakqx3R/oYgvs/OTVZH7a0+v7yvy5PP11GkD6+YfPSZel5r1lbtXbnOw5NTrvlySeS9V1BX975NwMfi4hDgNcCF0o6BLgEmBMRBwNzyttmtpOoGf6IWBIR95XX1wILgPHAGcDscrTZwJnNatLMGq9fn/klTQGOAO4GxkbEkrK0lOJjgZntJPocfkl7Aj8GPhwRayprUfwQYK8fbCXNkDRX0txuNtbVrJk1Tp/CL2kIRfCvi4iflIOXSRpX1scBy3ubNiJmRURXRHQNocYvMppZy9QMvyQB3wIWRMTlFaWbgOnl9enAjY1vz8yapeZPd0s6Afgd8CCwtRz8SYrP/TcAk4CnKXb1rUzdV64/3V3LoNGjkvVn3/KK9PTd1R/Dvb/3hwH1ZDun/vx0d839/BFxB1Dtzpxks52Uj/Azy5TDb5Yph98sUw6/WaYcfrNMOfxmmfJPd3eALc8lD49g1LfvalEnlhO/85tlyuE3y5TDb5Yph98sUw6/WaYcfrNMOfxmmXL4zTLl8JtlyuE3y5TDb5Yph98sUw6/WaYcfrNMOfxmmXL4zTLl8JtlyuE3y5TDb5Yph98sUw6/WaYcfrNMOfxmmaoZfkkTJf1G0sOSHpJ0cTl8pqTFkuaVl9Ob366ZNUpfTtqxGfhYRNwnaSRwr6Rby9pXIuLLzWvPzJqlZvgjYgmwpLy+VtICYHyzGzOz5urXZ35JU4AjgLvLQRdJekDSNZL2rTLNDElzJc3tZmNdzZpZ4/Q5/JL2BH4MfDgi1gBXAwcBUynWDC7rbbqImBURXRHRNYShDWjZzBqhT+GXNIQi+NdFxE8AImJZRGyJiK3AN4Cjm9emmTVaX7b2C/gWsCAiLq8YPq5itLcC8xvfnpk1S1+29h8PnAs8KGleOeyTwDmSpgIBLAQ+0JQOzawp+rK1/w5AvZRubnw7ZtYqPsLPLFMOv1mmHH6zTDn8Zply+M0y5fCbZcrhN8uUw2+WKYffLFMOv1mmHH6zTDn8Zply+M0y5fCbZUoR0bqZSc8CT1cMGgOsaFkD/dOpvXVqX+DeBqqRvU2OiP36MmJLw7/DzKW5EdHVtgYSOrW3Tu0L3NtAtas3r/abZcrhN8tUu8M/q83zT+nU3jq1L3BvA9WW3tr6md/M2qfd7/xm1iYOv1mm2hJ+SadJelTS45IuaUcP1UhaKOnB8rTjc9vcyzWSlkuaXzFslKRbJT1W/u31HIlt6q0jTtueOK18W5ddp53uvuWf+SUNAv4MnAI8A9wDnBMRD7e0kSokLQS6IqLtB4RIOhFYB1wbEYeVw74IrIyIL5QvnPtGxL90SG8zgXXtPm17eTapcZWnlQfOBN5NG5ddoq+zaMNya8c7/9HA4xHxZERsAn4AnNGGPjpeRNwOrOwx+Axgdnl9NsWTp+Wq9NYRImJJRNxXXl8LbDutfFuXXaKvtmhH+McDiypuP0MbF0AvArhF0r2SZrS7mV6MjYgl5fWlwNh2NtOLmqdtb6Uep5XvmGU3kNPdN5o3+O3ohIg4EngjcGG5etuRovjM1kn7avt02vZW6eW08n/TzmU30NPdN1o7wr8YmFhxe0I5rCNExOLy73Lgp3TeqceXbTtDcvl3eZv7+ZtOOm17b6eVpwOWXSed7r4d4b8HOFjSAZJ2B84GbmpDHzuQNKLcEIOkEcCpdN6px28CppfXpwM3trGX7XTKadurnVaeNi+7jjvdfUS0/AKcTrHF/wngU+3ooUpfBwL3l5eH2t0bcD3FamA3xbaR9wKjgTnAY8CvgFEd1Nt3gQeBByiCNq5NvZ1AsUr/ADCvvJze7mWX6Ksty82H95plyhv8zDLl8JtlyuE3y5TDb5Yph98sUw6/WaYcfrNM/T9q8ZCGzUFVpwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114dc5080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the model from disk (and analyze it)\n",
    "filename = './model_2019_01_28_16_36_20.csv'\n",
    "model_read_from_file = read_model(filename)\n",
    "print_model(model_read_from_file, funcs)\n",
    "\n",
    "\n",
    "# Analysis of incorrectly labelled images\n",
    "print_incorrectly_labelled_examples(X_dev, Y_dev, Y_prediction_dev, image_size)"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "XaIWT",
   "launcher_item_id": "zAgPl"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
